{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c713fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, asin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a1214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv('weather.csv')\n",
    "df_spray = pd.read_csv('spray.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe48072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse date into year, month and day\n",
    "def parsedate(df):\n",
    "    df = df.copy()\n",
    "    df['Year'] = pd.DatetimeIndex(df['Date']).year\n",
    "    df['Month'] = pd.DatetimeIndex(df['Date']).month\n",
    "    df['Day'] = pd.DatetimeIndex(df['Date']).day\n",
    "    return df   \n",
    "\n",
    "df_weather = parsedate(df_weather)\n",
    "df_spray = parsedate(df_spray)\n",
    "df_test = parsedate(df_test)\n",
    "df_train = parsedate(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fbdb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nearest Neighbour analysis with Haversine Distance\n",
    "\n",
    "def dist(lat1, lon1, lat2, lon2): \n",
    "    R = 6371\n",
    "    dLat = np.radians(lat2 - lat1)\n",
    "    dLon = np.radians(lon2 - lon1)\n",
    "    lat1 = np.radians(lat1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    a = np.power(np.sin(dLat/2), 2) + np.multiply(np.cos(lat1), np.multiply(np.cos(lat2), np.power(np.sin(dLon/2), 2)))\n",
    "    c = 2*np.arcsin(np.sqrt(a))\n",
    "    km = R * c\n",
    "    return km\n",
    "\n",
    "def station1or2(df):\n",
    "    df['lat1']=41.995  \n",
    "    df['lat2']=41.786   \n",
    "    df['lon1']=-87.933  \n",
    "    df['lon2']=-87.752  \n",
    "    df['dist1'] = dist(df.Latitude.values, df.Longitude.values, df.lat1.values, df.lon1.values) \n",
    "    df['dist2'] = dist(df.Latitude.values, df.Longitude.values, df.lat2.values, df.lon2.values)\n",
    "    indicator = np.less_equal(df.dist1.values, df.dist2.values) \n",
    "    df_station = np.ones(df.shape[0])\n",
    "    df_station[indicator==0]=2\n",
    "    df['Station']=df_station     \n",
    "    df.drop(['dist1', 'dist2', 'lat1', 'lat2', 'lon1', 'lon2' ], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "df_train = station1or2(df_train)\n",
    "df_test = station1or2(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116457b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop useless features\n",
    "\n",
    "df_train = df_train.drop(['Address', 'Block', 'Street', 'AddressNumberAndStreet', 'AddressAccuracy', 'NumMosquitos'], axis =1)\n",
    "df_test = df_test.drop(['Address', 'Block', 'Street', 'AddressNumberAndStreet', 'AddressAccuracy'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6acd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning Weather \n",
    "\n",
    "df_weather.replace(['M','-'], [np.nan, np.nan], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fa1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop features with too many nan values\n",
    "\n",
    "df_weather  = df_weather.drop(['Water1', 'SnowFall', 'Depth', 'CodeSum'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a11a104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station         0\n",
       "Date            0\n",
       "Tmax            0\n",
       "Tmin            0\n",
       "Tavg           11\n",
       "DewPoint        0\n",
       "WetBulb         4\n",
       "Heat           11\n",
       "Cool           11\n",
       "PrecipTotal     2\n",
       "StnPressure     4\n",
       "SeaLevel        9\n",
       "ResultSpeed     0\n",
       "ResultDir       0\n",
       "AvgSpeed        3\n",
       "Year            0\n",
       "Month           0\n",
       "Day             0\n",
       "Depart          0\n",
       "Sunset          0\n",
       "Sunrise         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill sensable missing data in station 2 with values from station 1\n",
    "\n",
    "dfs = df_weather[['Depart', 'Sunset', 'Sunrise']].fillna(method = 'ffill')\n",
    "df_weather = df_weather.drop( columns = ['Depart', 'Sunset', 'Sunrise'])\n",
    "df_weather = pd.concat([df_weather, dfs], axis=1)\n",
    "\n",
    "df_weather.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe7562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nan for Traces of precipitation\n",
    "\n",
    "df_weather.replace(['  T'], [0.01], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bdee497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace nan value of Heat and cool missing in station 2 with station 1 values\n",
    "\n",
    "dfa = df_weather[['Heat', 'Cool']].fillna(method = 'ffill')\n",
    "df_weather = df_weather.drop( columns = ['Heat', 'Cool'])\n",
    "df_weather = pd.concat([df_weather, dfa], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41f83ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\get gd nub\\AppData\\Local\\Temp\\ipykernel_14168\\1028224986.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_weather = df_weather.fillna(df_weather.median())\n"
     ]
    }
   ],
   "source": [
    "#replace nan value of missing values with avergers with median\n",
    "\n",
    "df_weather = df_weather.fillna(df_weather.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7045f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with duplicates in data\n",
    "\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_test = df_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9bb15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies Species\n",
    "\n",
    "df_train.Species.unique()\n",
    "df_train.Species.value_counts()\n",
    "\n",
    "dummies_train = pd.get_dummies(df_train['Species'])\n",
    "df_train = pd.concat([df_train, dummies_train], axis=1)\n",
    "\n",
    "dummies_test = pd.get_dummies(df_test['Species'])\n",
    "df_test = pd.concat([df_test, dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6aa1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dummies Trap\n",
    "\n",
    "df_train.Trap.unique()\n",
    "df_train.Trap.value_counts()\n",
    "\n",
    "dummies_train = pd.get_dummies(df_train['Trap'])\n",
    "df_train = pd.concat([df_train, dummies_train], axis=1)\n",
    "\n",
    "dummies_test = pd.get_dummies(df_test['Trap'])\n",
    "df_test = pd.concat([df_test, dummies_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2660521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge weather and train/ test\n",
    "\n",
    "df_train_merged = df_train.merge(df_weather, on=['Date', 'Station'], how=\"left\")\n",
    "\n",
    "df_test_merged = df_test.merge(df_weather, on=['Date', 'Station'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc22ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop useless features\n",
    "\n",
    "df_train_merged  = df_train_merged.drop(['Species', 'Trap', 'Date'], axis =1)\n",
    "df_test_merged  = df_test_merged.drop(['Species', 'Trap', 'Date'], axis =1)\n",
    "\n",
    "df_test_merged.to_csv(\"df_test_merged.csv\")\n",
    "df_train_merged.to_csv(\"df_train_merged.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
